"""Various utility functions."""

import itertools
import os

import numpy as np
from scipy.linalg import qr
from numpy.linalg import solve, inv
from numpy import dot
import matplotlib.pyplot as plt

def get_path(options, base, extension):
    """Return a path, using out_dir and out_postfix from options. The final
    path is thus:
      out_dir/{base}_{out_postfix}.{extension}
    """
    return os.path.join(options.out_dir, 
                        "%s_%s.%s" % (base, options.out_postfix, extension))

def redirect(filelike, path, append=False):
    """Redirect the output from a file/file-like object to the file identified
    in path. If append is True, open path with append flags, otherwise
    overwrite if file exists. Example usage that redirects all print commands
    to the given file:

    redirect(sys.stdout, "output_dump_%d.txt" % os.getpid())
    """
    flags = os.O_APPEND | os.O_CREAT if append else os.O_WRONLY | os.O_CREAT
    fd = os.open(path, flags)
    fd2 = filelike.fileno()
    os.dup2(fd, fd2)
 
def qr_solve(a, b, overwrite_a=False, lwork=None, mode='full', pivoting=False):
    """Similart to numpy.linalg.solve, but uses QR decomposition rather than LU
    decomposition. Slower but more numerically stable. The arguments following
    a and b are passed on to scipy.linalg.qr """
    Q,R = qr(a, overwrite_a=overwrite_a, lwork=lwork, mode=mode,
                       pivoting=pivoting)
    c = dot(Q.T,b)
    #x = np.linalg.solve(R,c) 
    x = dot(inv(R),c)
    return x

def plot_time_series(series, formats, labels, show=True):
    fig = plt.figure()
    if type(series) == type(formats) == type(labels) == list:
        for s,f,l in zip(series, formats, labels):
            s.plot(style=f, label=l)
    else:
        series.plot(style=formats, label=labels)
        
    plt.legend()
    if show:
        plt.show()

def flatten(*lists):
    """Return a flattened version of the inputs. Only one level of nesting,
    lists with sublists will not be flattened."""
    return list(itertools.chain(*lists))

def mean_absolute_percent_error(forecasted, observed):
    """Mean absolute percentage error is an error measure typically used when
    comparing forecaster performance."""
    if np.any(observed == 0):
        raise ValueError("Don't know how to calculate MAPE when the " \
                         "observed value is 0.") 
    all_errors = (abs((observed - forecasted) / observed))
    return all_errors.sum() / len(observed) * 100

mape = mean_absolute_percent_error

def scale(data):
    """Scales data to the range [0,1] along the rows."""
    return np.transpose(np.array([ (data[:,i] - \
                                    min(data[:,i]))/(max(data[:,i]) - min(data[:,i])) \
                                    for i in range(data.shape[1]) ]))

# Based on Alex Thomas' suggestion on http://stackoverflow.com/questions/36932/
# (whats-the-best-way-to-implement-an-enum-in-python), which creates an Enum
# class instance on-the-fly. Contrary to the original suggestion, this
# implementation can be pickled.
class Enum(object):
    """Implements an enum in Python. Usage:
    numbers = enum('ZERO', 'ONE', 'TWO', NOT_THREE=4)"""

    def __init__(self, *sequential, **named):
        enums = dict(zip(sequential, range(len(sequential))), **named)
        for (name, value) in enums.iteritems():
            object.__setattr__(self, name, value)

def bound(lower, upper, current):
    """Bound current in [lower, upper]."""
    return max(lower, min(upper, current))

def indicer(*args):
    """Return a dict where 'args' are the keys and the values are integers
    representing the position of each argument in 'args'.

    Example:
    indicer('one', 'two', 'three')
    returns this dict:
    {'one': 0, 'two': 1, 'three': 2}

    The returned dict can be used for as a lookup for systematic manipulation
    of the elements of an array (e.g. a genome) given the name, but not the
    position, of each element."""
    return dict([(args[i], i) for i in range(len(args))])
 
class Normalizer(object):
    """Normalizes a dataset. Upon initialization, new data can be passed in and
    "normalized" or expanded using the scale and offset parameters of the
    original dataset.

    For two-dimensional data, the normalizer behaves similar to numpy.min: if
    no axis argument is given, flatten the array. Otherwise normalize along the
    given axis.

    An integer dataset must be cast to float before it can be normalized. This
    class will not do that for you."""


    def __init__(self, dataset, axis=None):
        """Initialize the Normalizer with the data in 'dataset'. 'dataset' must
        support matrix addition and division (e.g. numpy.array, but not Python
        lists). axis is the axis along which to normalize (None = flatten)"""
        self._raw_data = dataset
        # Try using the min() method if available, as this allows classes to
        # define their own sorting, and also works with scikits.timeseries.
        try:
            self._offset = dataset.min(axis=axis)
            self._range = dataset.max(axis=axis) - self._offset
        except AttributeError:
            self._offset = np.min(dataset, axis=axis)
            self._range = np.max(dataset, axis=axis) - self._offset
        self._empty_range()
        self._shape_params(axis)
        self._normalized = self.normalize(self._raw_data)

    def _shape_params(self, axis):
        """Explicitly set the shape of the parameters, otherwise matrix
        subtraction and division won't work as intended."""
        if axis is None or axis == 0:
            return
        elif axis == 1:
            self._offset.shape = (self._offset.shape[0], 1)
            self._range.shape = (self._range.shape[0], 1)
        else:
            raise ValueError("Normalizer can't handle axis '%s', it only " \
                             "knows how to handle axes 'None', '0' and '1'." % \
                             axis)

    def _empty_range(self):
        """Handle the case where all values in a dataset are the same, so the
        range is 0."""
        try:
            self._range[self._range == 0] = 1
        except TypeError:
            if self._range == 0:
                self._range = 1
                             
    @property
    def normalized(self):
        """The normalized version of the dataset passed to the __init__
        function. This is a read-only property."""
        return self._normalized

    @property
    def raw(self):
        """Returns the dataset passed in as an argument to the __init__
        function. This is a read-only property."""
        return self._raw_data
    
    def normalize(self, data):
        """Scale and offset 'data' according to the normalization parameters
        (range and offset) determined by the dataset passed as argument to the
        __init__ function. Use the 'normalized' property if you need the
        normalized version of the original dataset."""
        return (data - self._offset) / self._range

    def expand(self, data):
        """Expand 'data' by multiplying with the range and shifting with the
        offset determined by the dataset passed as argument to the __init__
        function. Use the 'raw' property if you want the original dataset."""
        return data * self._range + self._offset


if __name__ == "__main__":
    from unittest import main
    main(module="test_" + __file__[:-3])
    
